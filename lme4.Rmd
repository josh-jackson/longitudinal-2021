---
title: "lme4"
output:
  distill::distill_article:
    toc: true
    toc_depth: 2
    mathjax: "https://cdn.bootcss.com/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_HTMLorMML"
    self_contained: false 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning = FALSE,
  message = FALSE)

library(rmarkdown)
library(tibble)
library(tidyverse)
```

# lme4 
The basic function we will work with is lmer from the lme4 package

```{r}
library(lme4)
```

The package was developed to be similar to the lm function. The code will be similar to the formula for the combined model

Code for empty/null/intercept only model

```{r, eval= FALSE}

lmer(Y ~ 1 + (1 | subjects), data=example)
```

Level 1
  $$ {Y}_{ti} = \beta_{0i}  +\varepsilon_{ti} $$
  
 Level 2
 $$ {\beta}_{0i} = \gamma_{00} + U_{0i} $$
 
 
 Combined 
 $$ {Y}_{ti} = \gamma_{00} + U_{0i}  + \varepsilon_{ti} $$
 
1 is the way to reference the intercept. All additional fixed effects go outside the parentheses. Inside the parentheses are the random effects and residual terms. To the right of the vertical line is our level 1 residual term, which references the grouping variable. In this case, as with almost all longitudinal work, is the subject ID. To the left of the vertical line is the random effects we want to estimate. Right now this estimates only one random effect, one for the intercept.

It is possible to suppress a random intercept by putting a zero instead of a 1. If you do not put anything there the 1 is implied. 


```{r, eval = FALSE}
lmer(y ~ 1 + time + (1 + time | subjects), data=data)

lmer(y ~ time + (time | subjects), data=data)

```

### Example

```{r}
example <- read.csv("https://raw.githubusercontent.com/josh-jackson/longitudinal-2021/master/example.csv")
example$year <- example$week
```



```{r}
mod.1 <- lmer(SMN7 ~ 1 + (1 | ID), data=example)
summary(mod.1)
```



### How to calculate ICC? 


```{r}
0.001823/(0.001823 + 0.001302)
```

Performance package from the easystats suite is really nice

```{r}
library(performance) 
model_performance(mod.1)
```



## Exploring beyond the summary


```{r}
class(mod.1)
```



### what do the random effects look like? 


```{r, message = FALSE}
library(sjPlot)
plot_model(mod.1, type = "re")

```


coef = fixef + raneff


```{r}
glimpse(ranef(mod.1))
```


```{r}
glimpse(coef(mod.1))
```

```{r}
fixef(mod.1)
```

How do these relate? Lets calculate ID 6 intercept random effect

coef = fixef + raneff

```{r}


# coef for ID = 6 is 0.04724795  
0.106972 -0.0597240676 

```


To get residuals and fitted scores

```{r}
library(broom.mixed)
example.aug<- augment(mod.1, data = example)

paged_table(example.aug)

# .fitted	 = predicted values
# .resid	= residuals/errors
# .fixed	 = predicted values with no random effects

```


## Adding time to the MLM
### Fixed slope 
```{r}
mod.2f <- lmer(SMN7 ~ 1 + year + (1  | ID), data=example)
summary(mod.2f)
```
What does this look like graphically? 



### Random slope
```{r}
mod.2 <- lmer(SMN7 ~ 1 + year + (year  | ID), data=example)
summary(mod.2)
```

How does the intercept change from the random intercept only model? 

How do you interpret year? 

How did the random effects change? 


## Viewing equations
```{r}
library(texPreview)
library(equatiomatic)
extract_eq(mod.2) 
```



# Visualizing results (quickly)


There are many ways to do this. The parameters package paired with the see package, both from the easystats package, are useful in this regard. 

```{r}
library(parameters)
library(see)

result <- model_parameters(mod.2)

plot(result)

```


```{r}
result2 <- simulate_parameters(mod.2)
plot(result2, show_intercept = TRUE)
```




```{r}
result3 <- model_parameters(mod.2,  effects = "random")
plot(result3)
```


These graphs however just take your output and make it look nice, in that the same information is still on the results. If we want to say, plot the predcted line we need to do an additional step and FEED the data back into the model. In doing so we create predicted values for each person (or each value of our predictor X), and then can visualize our findings as we would with a regression line. (More on this in the graphing workshop).

To do so we are going to need to use the ggeffects package

```{r}
library(ggeffects)
p.mod2 <- ggpredict(mod.2, "year")
p.mod2
```


```{r}
plot(p.mod2)
```

The error band here says that we are less confident in the predicted value as we get from year 
~4 and beyond. 



If you want you can also get predicted lines for a particular individual. 

```{r}
p.r.mod2 <- ggpredict(mod.2, "year", type = "random", condition = c(Subject = 97))
p.r.mod2
```

```{r}
plot(p.r.mod2)
```


```{r}
p.r.mod3 <- ggpredict(mod.2, c("year","ID[sample=9]"), type = "random")
plot(p.r.mod3)
```




```{r}
plot_model(mod.2, type = "re", grid = FALSE, sort.est = TRUE)
```


We will eventually be doing all of this "by hand" but it is helpful to start thinking about what sort of effects you want to visualize/display. 

```{r}
P.gg <- ggplot(example.aug, aes(x= year, y = .fitted)) + geom_point() + stat_smooth(method = "lm")   

P.gg

```


# Testing models
REML comparison, which again is what we need to compare random effects. ML is not good for comparing models with different random effects. 

```{r}
anova(mod.2f, mod.2)
```

Why is there a 2df difference? 


also you can see the non-REML fit info here: 

```{r}
glance(mod.2f)
```

Again, the performance package is nice for model fit, which model comparison is a part of

```{r}
compare_performance(mod.2f, mod.2)
```



### Why treating time is so important

Time with a different scale. How do we interpret? And what changes? 

```{r}
example$year.n <- (example$year - 30)
  
mod.2n <- lmer(SMN7 ~ 1 + year.n + (year.n  | ID), data=example)
summary(mod.2n)
```
What happened? 


### Calculation of fixed paramter CIs

From the parameters package, which is part of the easy stats suite

```{r}
library(parameters)
model_parameters(mod.2)
```

Give standard estimates. However, robust estimates can be done through a sandwich estiamtion (note the pacakge clubSandwich needs to be installed):

```{r}
model_parameters(
  mod.2, 
  robust = TRUE, 
  vcov_estimation = "CR", 
  vcov_type = "CR1"
)
```

```{r}
bootstrap_parameters(
  mod.2,
  iterations = 1000,
  centrality = "median",
  ci = 0.95,
  ci_method = "quantile",
  test = "p-value"
)
```


### p -values
The author of the package dislikes p-values. So they are not included. But what if you need them? Well, CIs. But if pressed you can use the parameters package: 

```{r}
p_value(mod.2)
```
lmertest is another package that does this but it also causes conflicts with standardly used packages so I would refrain from using. 


### Model assumption tests

```{r}
performance::check_model(mod.2, panel = FALSE)
```

### posterior predictions

```{r}
pp_check(mod.2)
```



# Random effects 

### Calculation of random effect confidence interval

Conveys the predicted range around each fixed effect in which 95% of the sample individuals are predicted to fall. 

95% random effect = fixed effect plus minus 1.96 * random standard deviation

How to calculate? 

1. Intercept $$\gamma_{00} \pm  1.96  *  \tau_{U_{0i}}$$

```{r}
0.1193933 + (1.96 * 0.240217) 
0.1193933 - (1.96 * 0.240217) 
```


2. Slope $$\gamma_{10} \pm  1.96  *  \tau_{U_{1i}}$$
```{r}
0.0004891 + (1.96 * 0.007745) 
0.0004891 - (1.96 * 0.007745) 
```



## Individual level random effects

Are the intercept random effects the same as the model with only the intercept? Why or why not? 


```{r}
glimpse(ranef(mod.2))
```


### Using simulations to get better estimates of confidence around our estimates

```{r}
library(broom.mixed)
random_params <- tidy(mod.2,  effects = "ran_vals", conf.int=TRUE)
glimpse(random_params)
```




```{r}
library(merTools)
FEsim(mod.2)
```


```{r}
re.sim <- REsim(mod.2)
head(re.sim)
```


This can be used to create CIs for each individual random effect (and fixed effect). What is the confidence interval around person 6's intercept estimate compared to person 2000 who has 25 repeated measurements? 

### Caterpillar plots

Look through these different methods of getting random effects. 


```{r}
p1 <- plotREsim(re.sim)
p1
```


### Density of individual random effects

```{r}
p1.gg1 <- re.sim %>% 
  filter(term == "(Intercept)") 

ggplot(p1.gg1, aes(mean)) +
  geom_density()
```



```{r}
p1.gg2 <- re.sim %>% 
  filter(term == "year") 


ggplot(p1.gg2, aes(mean)) +
  geom_density()
```




## Predictions and prediction intervals

Predict function is deterministic and uses only the fixed effects (i.e. does not include random effects in the predictions). It does not do prediction in the typical sense where you are predicting *new* individual's scores. 

Simulate is non-deterministic because it samples random effect values for all subjects and then samples from the conditional distribution. Simulation is needed to create true predictions. 




### Predictions and prediction intervals
Predict function is deterministic and uses only the fixed effects (i.e. does not include random effects in the predictions). It does not do prediction in the typical sense where you are predicting *new* individual's scores. 

Simulate is non-deterministic because it samples random effect values for all subjects and then samples from the conditional distribution. Simulation is needed to create true predictions. 

Short of a fully Bayesian analysis, bootstrapping is the gold-standard for deriving prediction intervals/bands (ie where would a new person score given X), but the time required is typically high.

In order to generate a proper prediction (for either a new person or a new observation within a person), a prediction must account for three sources of uncertainty in mixed models:

1. the residual (observation-level) variance,
2. the uncertainty in the fixed coefficients, and
3. the uncertainty in the variance parameters for the random effects

Does so by:
1. extracting the fixed and random coefficients
2. takes n draws from the multivariate normal distribution of the fixed and random coefficients (separately)
3. calculates the linear predictor for each row in newdata based on these draws, and
4. incorporates the residual variation  
then: 
5. returns newdata with the lower and upper limits of the prediction interval and the mean or median of the simulated predictions



```{r, warning=FALSE}
library(merTools)
# see also their shiny app: shinyMer(mod.1)

PI <- predictInterval(merMod = mod.2, newdata = example, level = 0.9, n.sims = 100, stat = "median", include.resid.var = TRUE)
head(PI)
```




